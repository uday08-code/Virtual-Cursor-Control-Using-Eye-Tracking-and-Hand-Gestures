Final-Year-Project

ğŸ‘ğŸ–± Virtual Cursor Control Using Eye Tracking and Hand Gestures

This project aims to create a virtual mouse system that allows users to control the computer cursor using their eye movements and hand gestures. It provides a touchless, intuitive, and accessible way of interacting with the computer, especially useful for differently-abled users and in hands-free environments like surgeries, clean rooms, etc.

ğŸ“Œ Features

ğŸ‘ Eye tracking-based cursor control

âœ‹ Hand gesture-based click simulation

ğŸ§  Real-time detection using computer vision

ğŸ’» Uses webcam as the only input device

ğŸ§© Easy-to-use, lightweight, and customizable

ğŸ›  Technologies Used

Python 3.x

OpenCV â€“ For image processing and webcam capture

MediaPipe â€“ For real-time hand and face landmark detection

PyAutoGUI â€“ For controlling mouse movements and clicks

NumPy â€“ For matrix and numerical operations

ğŸ§ª How It Works

Webcam captures real-time video feed.

MediaPipe detects hand landmarks (for gestures) and face landmarks (for eyes).

Eye movement is used to move the cursor.

Finger gestures (like index and thumb pinch) are used to click or perform actions.

PyAutoGUI maps these gestures to actual mouse movements/clicks.
